---
title: "ST558Project2"
author: "Yuyao Liu"
date: "10/14/2020"
output: rmarkdown::github_document
params:
  weekday: "monday"
---

# Introduction

I will analyze the Online News Popularity Data. This dataset summarizes a heterogeneous set of features about articles published by Mashable in a period of two years. There are 61 variables in the dataset which contains 58 predictive attributes, 2 non-predictive attributes and one target variable 'share'. I choose some of the predictive variables that can contains most of the information. For example, I choose some variables of average values instead of minimum or maximum, so it may get rid of some outliers. Also, some variables are about sentiment polarity or subjectivity, I choose one variable of these two types that can represent most information about word tokens. Meanwhile, I deleted some variables that are highly correlated with some others. 

## Predictors: 

1. n_tokens_title: Number of words in the title

2. n_tokens_content: Number of words in the content 

3. n_non_stop_unique_tokens: Rate of unique non-stop words in the content 

4. num_hrefs: Number of links 

5. num_self_hrefs: Number of links to other articles published by Mashable 

6. num_imgs: Number of images 

7. num_videos: Number of videos 

8. average_token_length: Average length of the words in the content 

9. num_keywords: Number of keywords in the metadata 

10. data_channel_is_lifestyle: Is data channel 'Lifestyle'? 

11. data_channel_is_entertainment: Is data channel 'Entertainment'? 

12. data_channel_is_bus: Is data channel 'Business'? 

13. data_channel_is_socmed: Is data channel 'Social Media'? 

14. data_channel_is_tech: Is data channel 'Tech'? 

15. data_channel_is_world: Is data channel 'World'?

16. kw_avg_min: Worst keyword (avg. shares) 

17. kw_avg_max: Best keyword (avg. shares)

18. kw_avg_avg: Avg. keyword (avg. shares) 

19. self_reference_avg_sharess: Avg. shares of referenced articles in Mashable

20. LDA_00: Closeness to LDA topic 0 

21. LDA_01: Closeness to LDA topic 1 

22. LDA_02: Closeness to LDA topic 2 

23. LDA_03: Closeness to LDA topic 3 

24. LDA_04: Closeness to LDA topic 4

25. global_rate_positive_words: Rate of positive words in the content 

26. global_rate_negative_words: Rate of negative words in the content 

27. avg_positive_polarity: Avg. polarity of positive words 

28. avg_negative_polarity: Avg. polarity of negative words 

29. title_subjectivity: Title subjectivity 

30. title_sentiment_polarity: Title polarity 

## Response/Target

shares: Number of shares

## Goal

The goal is to predict the number of shares(`shares`) in social networks. I will use regression tree and boosted tree to predict shares, and compare them using test set. 

```{r, message=FALSE}
library(rmarkdown)
library(tidyverse)
library(caret)
library(corrplot)
```

# Data

```{r, message=FALSE}
path <- file.path(getwd(), "OnlineNewsPopularity.csv")
temp_news <- read_csv(file = path)
weekday <- vector()
for(i in seq_len(nrow(temp_news))){
  if (temp_news$weekday_is_monday[i] == 1){
    weekday[i]  <- "monday"
  }
  else if (temp_news$weekday_is_tuesday[i] == 1){
    weekday[i]  <- "tuesday"
  }
  else if (temp_news$weekday_is_wednesday[i] == 1){
    weekday[i]  <- "wednesday"
  }
  else if (temp_news$weekday_is_thursday[i] == 1){
    weekday[i]  <- "thursday"
  }
  else if (temp_news$weekday_is_friday[i] == 1){
    weekday[i]  <- "friday"
  }
  else if (temp_news$weekday_is_saturday[i] == 1){
    weekday[i]  <- "saturday"
  }
  else if(temp_news$weekday_is_sunday[i] == 1){
    weekday[i]  <- "sunday"
  }
}
temp_news <- cbind(temp_news, weekday)
news <- temp_news %>% filter(weekday == params$weekday) %>% select(n_tokens_title, n_tokens_content, n_non_stop_unique_tokens, num_hrefs, num_self_hrefs, num_imgs, num_videos, average_token_length, num_keywords, data_channel_is_lifestyle, data_channel_is_entertainment, data_channel_is_bus, data_channel_is_socmed,data_channel_is_tech,data_channel_is_world,kw_avg_min, kw_avg_max,kw_avg_avg,self_reference_avg_sharess,LDA_00,LDA_01,LDA_02, LDA_03, LDA_04, global_rate_positive_words,global_rate_negative_words,avg_positive_polarity,avg_negative_polarity,title_subjectivity,title_sentiment_polarity,shares)
news$data_channel_is_lifestyle <- as.factor(news$data_channel_is_lifestyle)
news$data_channel_is_entertainment <- as.factor(news$data_channel_is_entertainment)
news$data_channel_is_bus <- as.factor(news$data_channel_is_bus)
news$data_channel_is_socmed <- as.factor(news$data_channel_is_socmed)
news$data_channel_is_tech <- as.factor(news$data_channel_is_tech)
news$data_channel_is_world <- as.factor(news$data_channel_is_world)
set.seed(558)
train <- sample(1:nrow(news), size = nrow(news)*0.7) 
test <- dplyr::setdiff(1:nrow(news), train) 
newsTrain <- news[train, ]
newsTest <- news[test, ]
```

# Summarizations

## Summary

The summary of training data includes minimum, 1st quantile, median, mean, 3rd quantile and maximum. 

```{r}
sum_news <- select(newsTrain, -contains("data_channel"))
summary(sum_news)
```

## Correlation

We can explore the data using correlation especially how these variables as predictors are correlated with our target response `shares`. 

Due to the large amount of variables, we may visualize them as groups. The first nine variables are about numbers. Let's see the correlation of first nine variables and `shares`.

```{r}
corr1 <- select(sum_news, 1:9, shares) %>% cor()
corrplot(corr1)
```

Most of variables are not highly correlated with others.


Let's see the variables about the content and word use and response `shares`.

```{r}
corr2 <- select(sum_news, 10:18, shares) %>% cor()
corrplot(corr2)
corr3 <- select(sum_news, -c(1:18)) %>% cor()
corrplot(corr3)
```

**All the predictors are little correlated to `shares`. **

# Modeling

## Nonlinear model

### Regression tree

The first model I create is a tree-based model chosen using leave one out cross validation. The response for this data is continuous, so I use regression tree model. 

**How do we fit the regression tree model?**

We fit the model using greedy algorithm. For every possible value of each predictor, find residual sum of squares and minimize them. 

I standardize the numeric predictors by centering
and scaling. Meanwhile, I determine tuning parameter choises using leave one out cross validation. 

The final chosen model is: 

```{r}
set.seed(558)
regTree <- train(shares ~ ., data = newsTrain, method = "rpart",
trControl = trainControl(method = "LOOCV"), preProcess = c("center", "scale"))
regTree
regTree$bestTune
```

### Boosted tree - Ensemble

The second model I create is a boosted tree model chosen using cross-validation. 

**How do we fit the boosting model?**

The trees grown sequentially. Each subsequent tree is grown on a modified version of original data. Predictions updated as trees grown. 

Procedure:

1. Initialize predictions as 0

2. Find the residuals (observed-predicted), call the set of them *r*

3. Fit a tree with *d* splits (*d*+1 terminal nodes) tresting the residuals as the response (which they are for the first fit)

4. Update predictions

5. Update residuals for new predictions and repeat *B* times

I also standardize the numeric predictors by centering and scaling and determine tuning parameter choises using cross-validation. 

The final chosen model is: 

```{r}
set.seed(558)
boostTree <- train(shares ~ ., data = newsTrain, method = "gbm",
trControl = trainControl(method = "cv", number = 10), preProcess = c("center", "scale"), verbose = FALSE)
boostTree
boostTree$bestTune
```

### Test and Compare

```{r}
tree_pred <- postResample(predict(regTree, newdata = newsTest), newsTest$shares)
boost_pred <- postResample(predict(boostTree, newdata = newsTest), newsTest$shares)
round(rbind(tree_pred, boost_pred), 4)
```

Choose the model with smaller root mean square error (RMSE), smaller mean absolute error (MAE) and bigger R squared. 

